{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-09T21:11:41.485071Z",
     "start_time": "2026-02-09T21:11:41.366288Z"
    }
   },
   "source": [
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# 1. Search for logged models ordered by class 1 recall\n",
    "# Note: Use the experiment ID corresponding to \"Wine_Quality_Locked_Dependencies\"\n",
    "# You can find the ID in the UI or by calling mlflow.get_experiment_by_name()\n",
    "experiment = mlflow.get_experiment_by_name(\"Wine_Quality_Locked_Dependencies\")\n",
    "experiment_id = '1'\n",
    "\n",
    "top_models = mlflow.search_logged_models(\n",
    "    experiment_ids=[experiment_id],\n",
    "    order_by=[{\"field_name\": \"metrics.test_recall\", \"ascending\": False}],\n",
    "    max_results=1,\n",
    ")\n",
    "\n",
    "best_model_record = top_models.iloc[0]\n",
    "model_name = \"wine_quality_champion_model\"\n",
    "\n",
    "# 2. Register the top model\n",
    "registered_version = mlflow.register_model(\n",
    "    model_uri=f\"runs:/{best_model_record.source_run_id}/model\",\n",
    "    name=model_name\n",
    ")\n",
    "\n",
    "# 3. Use MlflowClient to set description, tags, and alias\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=registered_version.version,\n",
    "    description=\"Top performing model selected based on Class 1 Recall on test set.\"\n",
    ")\n",
    "\n",
    "client.set_model_version_tag(\n",
    "    name=model_name,\n",
    "    version=registered_version.version,\n",
    "    key=\"role\",\n",
    "    value=\"champion\"\n",
    ")\n",
    "\n",
    "client.set_registered_model_alias(\n",
    "    name=model_name,\n",
    "    alias=\"champion\",\n",
    "    version=registered_version.version\n",
    ")\n",
    "\n",
    "print(f\"Model {model_name} version {registered_version.version} is now the Champion.\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'wine_quality_champion_model'.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T21:11:41.639908Z",
     "start_time": "2026-02-09T21:11:41.487382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_openml\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "# Initialize variables\n",
    "client = MlflowClient()\n",
    "model_name = \"wine_quality_champion_model\"\n",
    "\n",
    "# --- 1. Re-load Data to define X_test and y_test ---\n",
    "print(\"Loading dataset...\")\n",
    "wine = fetch_openml(\"wine-quality-red\", version=1, as_frame=True)\n",
    "X = wine.data\n",
    "y = (wine.target.astype(int) >= 6).astype(int)\n",
    "\n",
    "# Use the same random_state=42 to ensure the test set is identical to training\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# --- 2. Load the champion model using the alias ---\n",
    "print(f\"Loading champion model: {model_name}...\")\n",
    "champion_uri = f\"models:/{model_name}@champion\"\n",
    "loaded_champion = mlflow.sklearn.load_model(champion_uri)\n",
    "\n",
    "# --- 3. Make predictions on a small batch of test examples ---\n",
    "sample_X = X_test.head(5)\n",
    "predictions = loaded_champion.predict(sample_X)\n",
    "\n",
    "print(\"\\n--- Predictions on Sample Data ---\")\n",
    "results_df = sample_X.copy()\n",
    "results_df[\"predicted_quality\"] = predictions\n",
    "results_df[\"actual_quality\"] = y_test.head(5).values\n",
    "print(results_df[[\"predicted_quality\", \"actual_quality\"]])\n",
    "\n",
    "# --- 4. Retrieve and print metadata to verify ---\n",
    "print(\"\\n--- Champion Metadata Verification ---\")\n",
    "try:\n",
    "    model_metadata = client.get_model_version_by_alias(model_name, \"champion\")\n",
    "    print(f\"Alias 'champion' points to Version: {model_metadata.version}\")\n",
    "    print(f\"Source Run ID: {model_metadata.run_id}\")\n",
    "    print(f\"Tags: {model_metadata.tags}\")\n",
    "\n",
    "    # Verify the source (e.g., if it came from experiment 1)\n",
    "    run = mlflow.get_run(model_metadata.run_id)\n",
    "    print(f\"Original Experiment ID: {run.info.experiment_id}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving metadata: {e}\")"
   ],
   "id": "fe36e52d5167b499",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loading champion model: wine_quality_champion_model...\n",
      "\n",
      "--- Predictions on Sample Data ---\n",
      "      predicted_quality  actual_quality\n",
      "803                   0               1\n",
      "124                   0               0\n",
      "350                   0               1\n",
      "682                   0               0\n",
      "1326                  1               1\n",
      "\n",
      "--- Champion Metadata Verification ---\n",
      "Alias 'champion' points to Version: 2\n",
      "Source Run ID: 1002e0f1d57e4a438e08e62e42f7c3c0\n",
      "Tags: {'role': 'champion'}\n",
      "Original Experiment ID: 1\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
