{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adea0ae6",
   "metadata": {},
   "source": [
    "### This is the same code as what we have been using so far. import mlflow, load iris dataset, split test anbd train data. Then load up different values of the max_iter parameter of the classifier and then under this experiment, run different trainings based on different instances of the classifier. In mlflow UI, you should be able to see these different runs."
   ]
  },
  {
   "cell_type": "code",
   "id": "574b75c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T20:49:19.307383Z",
     "start_time": "2026-02-09T20:48:40.876619Z"
    }
   },
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_experiment(\"MLFlow: Search models with code\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the Iris dataset\n",
    "# X, y = datasets.load_iris(return_X_y=True)\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "wine = fetch_openml(\"wine-quality-red\", version=1, as_frame=True)\n",
    "X = wine.data\n",
    "y = (wine.target.astype(int) >= 6).astype(int)\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define the model hyperparameters\n",
    "max_iterations = [90, 100, 110, 150, 200, 250, 300, 350, 400, 450, 500]\n",
    "\n",
    "# Enable autologging for scikit-learn\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "for max_iter in max_iterations:\n",
    "    params = {\n",
    "        \"solver\": \"lbfgs\",\n",
    "        \"max_iter\": max_iter,\n",
    "        \"random_state\": 1234,\n",
    "    }\n",
    "    lr = LogisticRegression(**params)\n",
    "    lr.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kowshid/Documents/Repos/grad/ai-545-machine-learning-operations/.venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 500 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=500).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "2026/02/09 15:49:16 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/kowshid/Documents/Repos/grad/ai-545-machine-learning-operations/.venv/lib/python3.11/site-packages/mlflow/models/model.py:1209: FutureWarning: Saving scikit-learn models in the pickle or cloudpickle format requires exercising caution because these formats rely on Python's object serialization mechanism, which can execute arbitrary code during deserialization.The recommended safe alternative is the 'skops' format.\"\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "b5c2d780",
   "metadata": {},
   "source": [
    "### use the search_logged_models that takes as many experiment ids as you want it to have. Get the experiment ID if you click on any run under this experiment on mlflow UI. Here, we are filtering based on metrics_training_f1_score. you can do AND conditions here too if you want. Then we are sorting these models in descending order. and we want the top 5 models. Then select the 0th model as the top model. Extract the model id of that model. BTW, the search returns a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31e12b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_models = mlflow.search_logged_models(\n",
    "    experiment_ids=[\"1\"],\n",
    "    # filter_string=\"metrics.training_f1_score> 0.97\",\n",
    "    order_by=[{\"field_name\": \"metrics.training_f1_score\", \"ascending\": False}],\n",
    "    max_results=5,\n",
    ")\n",
    "best_model_id = top_models.iloc[0].model_id\n",
    "loaded_model = mlflow.sklearn.load_model(f\"models:/{best_model_id}\")\n",
    "print(f\"Best model ID: {best_model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874a4072",
   "metadata": {},
   "source": [
    "### Now you got the model id of the best performing model! Just load up the model and use it. No more clicking through the mlflow UI etc! You have automated the model selection now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74e56b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "predictions = loaded_model.predict(X_test)\n",
    "iris_feature_names = datasets.load_iris().feature_names\n",
    "result = pd.DataFrame(X_test, columns=iris_feature_names)\n",
    "result[\"actual_class\"] = y_test\n",
    "result[\"predicted_class\"] = predictions\n",
    "result[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai545",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
