{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-17T00:48:59.976006Z",
     "start_time": "2026-02-17T00:48:59.237459Z"
    }
   },
   "source": [
    "# [BLOCK 1: Setup and Data Loading]\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    precision_recall_curve, confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# 1. Setup MLflow\n",
    "TRACKING_URI = \"http://127.0.0.1:5000\"\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "EXPERIMENT_NAME = \"creditcardfraud-mlflow-lifecycle-v3\"\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# 2. Load Data\n",
    "# Assuming creditcard.csv is in the local directory\n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "\n",
    "# 3. Split Data (Stratified because fraud is rare)\n",
    "target_col = \"Class\"\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 4. Preprocessing Pipeline\n",
    "num_scale_cols = [\"Time\", \"Amount\"]\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[(\"scale\", StandardScaler(), num_scale_cols)],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "print(f\"Experiment '{EXPERIMENT_NAME}' is active.\")\n",
    "print(f\"Training Data Shape: {X_train.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 'creditcardfraud--mlflow-lifecycle-v3' is active.\n",
      "Training Data Shape: (227845, 30)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T00:50:38.182743Z",
     "start_time": "2026-02-17T00:48:59.977012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# [BLOCK 2: Training Loop - SAFE VERSION]\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, average_precision_score, precision_recall_curve\n",
    "\n",
    "# 1. SAFETY FIX: Create the directory explicitly\n",
    "if not os.path.exists(\"../assignment01/artifacts\"):\n",
    "    os.makedirs(\"../assignment01/artifacts\")\n",
    "    print(\"Created 'artifacts' directory.\")\n",
    "\n",
    "# Define the grid\n",
    "run_grid = [\n",
    "    {\"n_estimators\": 100, \"max_depth\": 5,  \"min_samples_split\": 2, \"min_samples_leaf\": 1, \"class_weight\": \"balanced\"},\n",
    "    {\"n_estimators\": 200, \"max_depth\": 10, \"min_samples_split\": 5, \"min_samples_leaf\": 2, \"class_weight\": \"balanced\"},\n",
    "    {\"n_estimators\": 300, \"max_depth\": 8,  \"min_samples_split\": 10, \"min_samples_leaf\": 4, \"class_weight\": \"balanced\"},\n",
    "    {\"n_estimators\": 400, \"max_depth\": 20, \"min_samples_split\": 2, \"min_samples_leaf\": 1, \"class_weight\": \"balanced\"},\n",
    "    {\"n_estimators\": 200, \"max_depth\": 6,  \"min_samples_split\": 20, \"min_samples_leaf\": 10, \"class_weight\": \"balanced\"},\n",
    "]\n",
    "\n",
    "def plot_pr_curve(y_true, y_proba, path):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_proba)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(recall, precision, marker='.', label='Random Forest')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend()\n",
    "    plt.savefig(path)\n",
    "    plt.close() # Close to save memory\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "for i, cfg in enumerate(run_grid, start=1):\n",
    "    try:\n",
    "        run_name = f\"rf_run_{i}_depth_{cfg['max_depth']}\"\n",
    "        print(f\"--> Processing Run {i}: {run_name}\")\n",
    "\n",
    "        model = RandomForestClassifier(random_state=42, n_jobs=-1, **cfg)\n",
    "        pipe = Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", model)])\n",
    "\n",
    "        with mlflow.start_run(run_name=run_name) as run:\n",
    "            # Tags & Params\n",
    "            mlflow.set_tags({\n",
    "                \"problem_type\": \"fraud_detection\",\n",
    "                \"model_family\": \"random_forest\",\n",
    "                \"run_purpose\": \"hyperparameter_tuning\" if i > 1 else \"baseline\"\n",
    "            })\n",
    "            mlflow.log_params(cfg)\n",
    "            mlflow.log_param(\"test_size\", 0.2)\n",
    "\n",
    "            # Train & Predict\n",
    "            pipe.fit(X_train, y_train)\n",
    "            y_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "            y_pred = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "            # Metrics\n",
    "            roc_auc = roc_auc_score(y_test, y_proba)\n",
    "            avg_precision = average_precision_score(y_test, y_proba)\n",
    "\n",
    "            mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "            mlflow.log_metric(\"pr_auc\", avg_precision)\n",
    "\n",
    "            # Artifacts (The likely crash point)\n",
    "            # 1. Confusion Matrix\n",
    "            cm = confusion_matrix(y_test, y_pred)\n",
    "            plt.figure(figsize=(5, 4))\n",
    "            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "            plt.title(f\"Confusion Matrix (Run {i})\")\n",
    "            cm_path = f\"artifacts/cm_{run.info.run_id}.png\"\n",
    "            plt.savefig(cm_path)\n",
    "            plt.close() # Important!\n",
    "            mlflow.log_artifact(cm_path, artifact_path=\"plots\")\n",
    "\n",
    "            # 2. PR Curve\n",
    "            pr_path = f\"artifacts/pr_{run.info.run_id}.png\"\n",
    "            plot_pr_curve(y_test, y_proba, pr_path)\n",
    "            mlflow.log_artifact(pr_path, artifact_path=\"plots\")\n",
    "\n",
    "            results.append({\n",
    "                \"run_id\": run.info.run_id,\n",
    "                \"params\": cfg,\n",
    "                \"pr_auc\": avg_precision,\n",
    "                \"roc_auc\": roc_auc\n",
    "            })\n",
    "            print(f\"    Finished. PR-AUC: {avg_precision:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"!!! CRASHED ON RUN {i} !!!\")\n",
    "        print(f\"Error Message: {e}\")\n",
    "        break # Stop the loop so you can see the error\n",
    "\n",
    "print(\"Loop Complete.\")"
   ],
   "id": "d1ba42269dcf6a46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Finished. PR-AUC: 0.7578\n",
      "üèÉ View run rf_run_5_depth_6 at: http://127.0.0.1:5000/#/experiments/1/runs/87e816de877d4356af7e9cf37b2061c0\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/1\n",
      "Loop Complete.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T00:50:38.234389Z",
     "start_time": "2026-02-17T00:50:38.202796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# [BLOCK 3: Analysis and Best Run Selection]\n",
    "\n",
    "# Convert results to DataFrame for easy comparison\n",
    "compare_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort by PR-AUC (Average Precision) as it's most important for imbalanced data\n",
    "compare_df = compare_df.sort_values(by=\"pr_auc\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"Experiment Comparison (Top 3):\")\n",
    "print(compare_df[[\"run_id\", \"pr_auc\", \"roc_auc\"]].head(3))\n",
    "\n",
    "# Select Best Run ID and Params\n",
    "best_run_id = compare_df.loc[0, \"run_id\"]\n",
    "best_params = compare_df.loc[0, \"params\"]\n",
    "best_metric = compare_df.loc[0, \"pr_auc\"]\n",
    "\n",
    "print(f\"\\nBest Run ID: {best_run_id} with PR-AUC: {best_metric:.4f}\")"
   ],
   "id": "1e17e0a57b69939e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Comparison (Top 3):\n",
      "                             run_id    pr_auc   roc_auc\n",
      "0  4aaaabbead584975afd714cd21226315  0.857466  0.959987\n",
      "1  7b5a3f9548104bd5bf6e02cdfbfb8cc1  0.840541  0.984031\n",
      "2  f321712bef3146c7a22fd107ae1e6aa6  0.814236  0.985024\n",
      "\n",
      "Best Run ID: 4aaaabbead584975afd714cd21226315 with PR-AUC: 0.8575\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T00:51:18.760110Z",
     "start_time": "2026-02-17T00:50:38.240699Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# [BLOCK 4: Retraining and Packaging Best Model]\n",
    "\n",
    "# We retrain the best config to ensure we have the live object for logging\n",
    "print(f\"Packaging best model with params: {best_params}\")\n",
    "\n",
    "model = RandomForestClassifier(random_state=42, n_jobs=-1, **best_params)\n",
    "pipe = Pipeline(steps=[(\"preprocess\", preprocess), (\"model\", model)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Create Input Example and Signature\n",
    "input_example = X_train.iloc[:5]\n",
    "y_proba_example = pipe.predict_proba(input_example)[:, 1]\n",
    "signature = infer_signature(input_example, y_proba_example)\n",
    "\n",
    "with mlflow.start_run(run_name=\"best_model_packaged\") as run:\n",
    "    mlflow.set_tag(\"run_purpose\", \"packaging_best_model\")\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # --- NEW: Calculate and Log Metrics for this specific run ---\n",
    "    # This ensures the metrics appear in the \"best_model_packaged\" row\n",
    "    y_proba_packaged = pipe.predict_proba(X_test)[:, 1]\n",
    "    roc_auc_packaged = roc_auc_score(y_test, y_proba_packaged)\n",
    "    pr_auc_packaged = average_precision_score(y_test, y_proba_packaged)\n",
    "\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc_packaged)\n",
    "    mlflow.log_metric(\"pr_auc\", pr_auc_packaged)\n",
    "    # ------------------------------------------------------------\n",
    "\n",
    "    # Log the Model with Signature and Input Example\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=pipe,\n",
    "        artifact_path=\"fraud_model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example\n",
    "    )\n",
    "\n",
    "    packaged_run_id = run.info.run_id\n",
    "    print(f\"Best model packaged in Run ID: {packaged_run_id}\")\n",
    "    print(f\"Metrics propagated -> PR-AUC: {pr_auc_packaged:.4f}, ROC-AUC: {roc_auc_packaged:.4f}\")"
   ],
   "id": "400a062a655a598e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model packaged in Run ID: ddcd484fcaea4f9fa1ee6800ab148248\n",
      "Metrics propagated -> PR-AUC: 0.8575, ROC-AUC: 0.9600\n",
      "üèÉ View run best_model_packaged at: http://127.0.0.1:5000/#/experiments/1/runs/ddcd484fcaea4f9fa1ee6800ab148248\n",
      "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/1\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T00:51:22.992630Z",
     "start_time": "2026-02-17T00:51:18.777451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# [BLOCK 5: Model Registry and Lifecycle Management]\n",
    "\n",
    "client = MlflowClient()\n",
    "MODEL_REGISTRY_NAME = \"CreditCardFraud_RF_Classifier\"\n",
    "\n",
    "# --- Version 1: The Champion (Production) ---\n",
    "print(\"Registering Version 1...\")\n",
    "# Register the model (this creates Version 1)\n",
    "model_v1 = mlflow.register_model(\n",
    "    model_uri=f\"runs:/{packaged_run_id}/fraud_model\",\n",
    "    name=MODEL_REGISTRY_NAME\n",
    ")\n",
    "time.sleep(2) # Pause to ensure registration completes\n",
    "\n",
    "# 1. Transition to Production\n",
    "client.transition_model_version_stage(\n",
    "    name=MODEL_REGISTRY_NAME,\n",
    "    version=model_v1.version,\n",
    "    stage=\"Production\"\n",
    ")\n",
    "\n",
    "# 2. Add Alias, Tag, and Comment\n",
    "client.set_registered_model_alias(MODEL_REGISTRY_NAME, \"champion\", model_v1.version)\n",
    "client.set_model_version_tag(MODEL_REGISTRY_NAME, model_v1.version, \"stage\", \"production\")\n",
    "client.update_model_version(\n",
    "    name=MODEL_REGISTRY_NAME,\n",
    "    version=model_v1.version,\n",
    "    description=\"Best model version 1\"\n",
    ")\n",
    "\n",
    "\n",
    "# --- Version 2: The Challenger (Staging) ---\n",
    "print(\"Registering Version 2...\")\n",
    "# Register the same model again to simulate a new version/challenger\n",
    "model_v2 = mlflow.register_model(\n",
    "    model_uri=f\"runs:/{packaged_run_id}/fraud_model\",\n",
    "    name=MODEL_REGISTRY_NAME\n",
    ")\n",
    "time.sleep(2)\n",
    "\n",
    "# 1. Transition to Staging\n",
    "client.transition_model_version_stage(\n",
    "    name=MODEL_REGISTRY_NAME,\n",
    "    version=model_v2.version,\n",
    "    stage=\"Staging\"\n",
    ")\n",
    "\n",
    "# 2. Add Alias, Tag, and Comment\n",
    "client.set_registered_model_alias(MODEL_REGISTRY_NAME, \"challenger\", model_v2.version)\n",
    "client.set_model_version_tag(MODEL_REGISTRY_NAME, model_v2.version, \"stage\", \"staging\")\n",
    "client.update_model_version(\n",
    "    name=MODEL_REGISTRY_NAME,\n",
    "    version=model_v2.version,\n",
    "    description=\"Best model challenger version 2\"\n",
    ")\n",
    "\n",
    "print(\"\\n--- Model Registry Status ---\")\n",
    "print(f\"Version {model_v1.version}: Alias='champion',   Tag='production', Desc='{model_v1.description}'\")\n",
    "print(f\"Version {model_v2.version}: Alias='challenger', Tag='staging',    Desc='{model_v2.description}'\")"
   ],
   "id": "b629236ed2416150",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fk/nsjj191d27x4bdt87fhyv1t00000gn/T/ipykernel_8379/1120417972.py:42: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
